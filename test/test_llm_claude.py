"""
Test script to verify LLM manager works with Anthropic Claude
"""
import sys
import os

# Add parent directory to Python path to access HelmBot modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def test_llm_manager():
    """Test the LLM manager with Anthropic Claude"""
    try:
        print("ğŸ§ª Testing LLM Manager with Anthropic Claude...")
        
        # Import and initialize
        from llm_manager import LLMManager
        from config import PROVIDER, DEFAULT_MODEL, GPT4_MODEL
        
        print(f"ğŸ“‹ Current provider: {PROVIDER}")
        print(f"ğŸ“‹ Default model: {DEFAULT_MODEL}")
        print(f"ğŸ“‹ Advanced model: {GPT4_MODEL}")
        
        # Initialize LLM manager
        llm_manager = LLMManager()
        
        # Get provider info
        provider_info = llm_manager.get_provider_info()
        print(f"âœ… Provider info: {provider_info}")
        
        # Test getting LLM instances
        print("\nğŸ”§ Testing LLM instance creation...")
        
        # Test default model
        llm_default = llm_manager.get_gpt35_llm()
        print(f"âœ… Default model LLM created: {type(llm_default).__name__}")
        
        # Test advanced model
        llm_advanced = llm_manager.get_gpt4_llm()
        print(f"âœ… Advanced model LLM created: {type(llm_advanced).__name__}")
        
        # Test a simple prompt
        print("\nğŸ’¬ Testing simple prompt...")
        test_prompt = "Say 'Hello from Claude!' in exactly 3 words."
        response = llm_default.invoke(test_prompt)
        print(f"âœ… Claude response: {response.content}")
        
        print("\nğŸ‰ All LLM manager tests passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_llm_manager()
    if not success:
        sys.exit(1)